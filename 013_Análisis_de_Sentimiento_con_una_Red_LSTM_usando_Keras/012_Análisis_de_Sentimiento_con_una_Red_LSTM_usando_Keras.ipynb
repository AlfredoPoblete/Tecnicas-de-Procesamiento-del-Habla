{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#AnÃ¡lisis de Sentimiento con una Red LSTM usando Keras\n",
        "##ğŸ¯ Objetivo\n",
        "En esta actividad vas a construir un modelo de red neuronal recurrente (RNN), especÃ­ficamente una LSTM, usando la API Keras de TensorFlow. El modelo leerÃ¡ frases en espaÃ±ol y clasificarÃ¡ su sentimiento como positivo o negativo.\n",
        "\n"
      ],
      "metadata": {
        "id": "qSvHGspZdXSi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ğŸ§° 1. PreparaciÃ³n del entorno\n",
        "Importamos las librerÃ­as necesarias. Si estÃ¡s en Google Colab, podÃ©s ejecutar la celda tal como estÃ¡."
      ],
      "metadata": {
        "id": "cy_gLJYldf5Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "R4KyRLqWdfn3"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ğŸ—‚ï¸ 2. Datos de entrenamiento\n",
        "Vamos a usar las mismas frases que en la actividad anterior, pero ahora procesadas como secuencias de palabras, no como bolsa de palabras."
      ],
      "metadata": {
        "id": "UpJwnXPUdtbA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KV8jghGzdSRj"
      },
      "outputs": [],
      "source": [
        "frases = [\n",
        "    \"La verdad, este lugar estÃ¡ increible! Me encantÃ³!\",\n",
        "    \"Una porquerÃ­a de servicio, nunca mÃ¡s vengo\",\n",
        "    \"Me encantan las mesas, lastima el baÃ±o que es un desastre\",\n",
        "    \"Me enviaron un producto llegÃ³ daÃ±ado. QuÃ© bajon\",\n",
        "    \"Todo impecable. De primera\",\n",
        "    \"QuÃ© afano, me cuentearon con el producto\",\n",
        "    \"Muy conforme con el resultado final\",\n",
        "    \"No me gustÃ³ para nada la experiencia\",\n",
        "    \"SuperÃ³ mis expectativas, Â¡gracias!\",\n",
        "    \"No lo recomiendo, mala calidad\",\n",
        "    \"Me vino todo roto, exijo una devolucion\",\n",
        "    \"Muy buen servicio, lo recomiendo\",\n",
        "    \"Todo impecable, llego en tiempo y forma\"\n",
        "\n",
        "]\n",
        "\n",
        "etiquetas = np.array([1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1])  # 1 = Positivo, 0 = Negativo"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##âœï¸ 3. TokenizaciÃ³n y vectorizaciÃ³n\n",
        "Con Keras, vamos a convertir las frases en secuencias de nÃºmeros, donde cada nÃºmero representa una palabra del vocabulario."
      ],
      "metadata": {
        "id": "fJ-RfP1kd3zw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TokenizaciÃ³n\n",
        "tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(frases)\n",
        "\n",
        "# Secuencias numÃ©ricas\n",
        "secuencias = tokenizer.texts_to_sequences(frases)\n",
        "\n",
        "# Padding para que todas las frases tengan la misma longitud\n",
        "maxlen = max(len(seq) for seq in secuencias)\n",
        "X = pad_sequences(secuencias, maxlen=maxlen, padding='post')\n",
        "\n",
        "# Convertimos las etiquetas\n",
        "y = np.array(etiquetas)"
      ],
      "metadata": {
        "id": "IdBIn62nd3gA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ğŸ§± 4. DefiniciÃ³n del modelo LSTM\n",
        "Vamos a usar una red con:\n",
        "\n",
        "* Capa de embedding (representaciÃ³n vectorial aprendida de cada palabra).\n",
        "\n",
        "* Una capa LSTM para captar la secuencia.\n",
        "\n",
        "* Una capa densa para clasificar."
      ],
      "metadata": {
        "id": "FfARMHgkeCUg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ParÃ¡metros\n",
        "vocab_size = len(tokenizer.word_index) + 1  # +1 por el token OOV\n",
        "embedding_dim = 16\n",
        "lstm_units = 32\n",
        "\n",
        "# Modelo\n",
        "modelo = Sequential([\n",
        "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=maxlen),\n",
        "    LSTM(units=lstm_units),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "modelo.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "modelo.summary()"
      ],
      "metadata": {
        "id": "qdBFUXe_eCsg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "49a06c89-7fc7-40f7-f2a7-222add0fd2f6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ğŸš€ 5. Entrenamiento\n",
        "Entrenamos el modelo por unas pocas Ã©pocas para ver resultados rÃ¡pidos en clase. Si tenÃ©s mÃ¡s tiempo o mÃ¡s datos, podÃ©s aumentarlas."
      ],
      "metadata": {
        "id": "M3TtQP9lePlH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelo.fit(X, y, epochs=20, batch_size=2, verbose=1)\n"
      ],
      "metadata": {
        "id": "IO9WfKXEePS3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5576169-0181-4e80-d5ca-ad11021150d7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.4139 - loss: 0.6949   \n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4940 - loss: 0.6928 \n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4284 - loss: 0.6942    \n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4575 - loss: 0.6923\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5461 - loss: 0.6872 \n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5325 - loss: 0.6848\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3950 - loss: 0.6865     \n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5534 - loss: 0.6654\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6195 - loss: 0.6413 \n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7788 - loss: 0.5538 \n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9579 - loss: 0.3782 \n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.2377 \n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.1781\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.1374\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.1089\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0883 \n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0556 \n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0359\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0220 \n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0255 \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c85d670de10>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ğŸ§ª 6. EvaluaciÃ³n con frases nuevas\n",
        "Ahora vamos a probar el modelo con frases no vistas y observar sus predicciones."
      ],
      "metadata": {
        "id": "KpqlBI4ReZv3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frases_nuevas = [\n",
        "    \"Muy buena atenciÃ³n, quedÃ© encantado\",\n",
        "    \"Horrible experiencia, no vuelvo mÃ¡s\",\n",
        "    \"Todo excelente, gracias por la atenciÃ³n\",\n",
        "    \"Me arrepiento completamente, fue un desastre\",\n",
        "    \"Un servicio impecable y rÃ¡pido\"\n",
        "]\n",
        "\n",
        "# Tokenizamos y convertimos\n",
        "secuencias_nuevas = tokenizer.texts_to_sequences(frases_nuevas)\n",
        "X_nuevo = pad_sequences(secuencias_nuevas, maxlen=maxlen, padding='post')\n",
        "\n",
        "# PredicciÃ³n\n",
        "predicciones = modelo.predict(X_nuevo)\n",
        "\n",
        "# Mostrar resultados\n",
        "for frase, pred in zip(frases_nuevas, predicciones):\n",
        "    clase = \"Positivo\" if pred[0] >= 0.5 else \"Negativo\"\n",
        "    print(f\"Frase: '{frase}' => Sentimiento predicho: {clase} ({pred[0]:.2f})\")\n"
      ],
      "metadata": {
        "id": "Bq7pY6EUeZd_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba45147f-a0e4-4bd5-f072-c4265f0e953b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step\n",
            "Frase: 'Muy buena atenciÃ³n, quedÃ© encantado' => Sentimiento predicho: Positivo (0.99)\n",
            "Frase: 'Horrible experiencia, no vuelvo mÃ¡s' => Sentimiento predicho: Negativo (0.04)\n",
            "Frase: 'Todo excelente, gracias por la atenciÃ³n' => Sentimiento predicho: Positivo (0.76)\n",
            "Frase: 'Me arrepiento completamente, fue un desastre' => Sentimiento predicho: Negativo (0.05)\n",
            "Frase: 'Un servicio impecable y rÃ¡pido' => Sentimiento predicho: Positivo (0.78)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ğŸ§  ReflexiÃ³n final\n",
        "##ğŸ‘‰ Â¿QuÃ© aprendimos?\n",
        "\n",
        "* CÃ³mo representar texto como secuencia de palabras usando Keras.\n",
        "\n",
        "* QuÃ© es una red LSTM y cÃ³mo recuerda el contexto.\n",
        "\n",
        "* CÃ³mo el orden de las palabras sÃ­ influye en el resultado.\n",
        "\n",
        "* Que las redes recurrentes pueden manejar frases mÃ¡s complejas que los MLP o perceptrones."
      ],
      "metadata": {
        "id": "TfghBPJPel0Y"
      }
    }
  ]
}