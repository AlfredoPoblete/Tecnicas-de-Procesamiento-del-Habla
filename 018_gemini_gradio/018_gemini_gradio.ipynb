{
  "nbformat": 4,
  "nbformat_minor": 5,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "title_cell"
      },
      "source": [
        "# Reconocimiento de Entidades Nombradas\n",
        "## Ejercicio Pr√°ctico - Procesamiento de Lenguaje Natural\n",
        "\n",
        "**Objetivos de Aprendizaje:**\n",
        "1. Implementar NER usando modelos pre-entrenados en espa√±ol\n",
        "2. Crear interfaces interactivas con Gradio\n",
        "3. Comparar enfoques: Transformers vs API Gemini\n",
        "4. Desarrollar prototipos r√°pidos para aplicaciones de PLN\n",
        "\n",
        "---\n",
        "**Entorno recomendado:** Google Colab o Amazon SageMaker Studio\n",
        "\n",
        "**Tiempo estimado:** 60-90 minutos"
      ],
      "id": "title_cell"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup_section"
      },
      "source": [
        "## Instalaci√≥n de Dependencias"
      ],
      "id": "setup_section"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "install_deps"
      },
      "outputs": [],
      "source": [
        "# Instalaci√≥n de librer√≠as necesarias\n",
        "%%capture\n",
        "!pip install -q transformers torch gradio google-genai"
      ],
      "id": "install_deps"
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar instalaci√≥n\n",
        "import sys\n",
        "print(f\"Python: {sys.version}\")\n",
        "print(\"Todas las dependencias instaladas correctamente\")"
      ],
      "metadata": {
        "id": "cJksfScFfyjN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9c053fb-0531-4c92-f2a1-4e59de3617b2"
      },
      "id": "cJksfScFfyjN",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n",
            "Todas las dependencias instaladas correctamente\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "config_section"
      },
      "source": [
        "## Configuraci√≥n de APIs\n",
        "\n",
        "### Para Google Colab:\n",
        "1. And√° a la barra lateral izquierda y hac√© clic en üîë (Secrets)\n",
        "2. Agrega una nueva clave: `GOOGLE_API_KEY`\n",
        "3. Pega tu API key de Google AI Studio\n",
        "\n",
        "### Para SageMaker Studio:\n",
        "1. Configura las variables de entorno en tu instancia\n",
        "2. O usa el m√©todo de input manual m√°s abajo"
      ],
      "id": "config_section"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "config_api",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67e0b64c-ce2f-434a-a098-def1c105661b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API Key cargada desde Google Colab Secrets\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configuraci√≥n de API Key para Gemini\n",
        "try:\n",
        "    # M√©todo 1: Google Colab Secrets\n",
        "    from google.colab import userdata\n",
        "    GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "    print(\"API Key cargada desde Google Colab Secrets\")\n",
        "except:\n",
        "    # M√©todo 2: Variables de entorno (SageMaker)\n",
        "    GOOGLE_API_KEY = os.environ.get('GOOGLE_API_KEY')\n",
        "    if GOOGLE_API_KEY:\n",
        "        print(\"API Key cargada desde variables de entorno\")\n",
        "    else:\n",
        "        print(\"No se encontr√≥ GOOGLE_API_KEY\")\n",
        "        print(\"Podes continuar solo con la parte de Transformers\")"
      ],
      "id": "config_api"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "part1_header"
      },
      "source": [
        "---\n",
        "# PARTE 1: NER con Transformers de Hugging Face\n",
        "\n",
        "Utilizaremos un modelo especializado en espa√±ol que puede identificar:\n",
        "- **PER**: Personas\n",
        "- **LOC**: Lugares\n",
        "- **ORG**: Organizaciones  \n",
        "- **MISC**: Miscel√°neo"
      ],
      "id": "part1_header"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "load_transformer_model",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5455c7c-7154-4077-ed14-29b8eaf92beb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üñ•Ô∏è  Dispositivo: CPU\n",
            "üì• Cargando modelo de NER para espa√±ol...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at mrm8488/bert-spanish-cased-finetuned-ner were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo mrm8488/bert-spanish-cased-finetuned-ner cargado exitosamente\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "import torch\n",
        "\n",
        "# Verificar disponibilidad de GPU\n",
        "device = 0 if torch.cuda.is_available() else -1\n",
        "print(f\"üñ•Ô∏è  Dispositivo: {'GPU' if device == 0 else 'CPU'}\")\n",
        "\n",
        "# Cargar modelo de NER en espa√±ol\n",
        "print(\"üì• Cargando modelo de NER para espa√±ol...\")\n",
        "MODEL_NAME = \"mrm8488/bert-spanish-cased-finetuned-ner\"\n",
        "\n",
        "try:\n",
        "    ner_pipeline = pipeline(\n",
        "        \"ner\",\n",
        "        model=MODEL_NAME,\n",
        "        aggregation_strategy=\"simple\",\n",
        "        device=device\n",
        "    )\n",
        "    print(f\"Modelo {MODEL_NAME} cargado exitosamente\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error al cargar modelo: {e}\")\n",
        "    ner_pipeline = None"
      ],
      "id": "load_transformer_model"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "test_transformer_ner"
      },
      "outputs": [],
      "source": [
        "# Texto de ejemplo con contexto argentino\n",
        "texto_ejemplo = \"\"\"\n",
        "Hola, soy Mar√≠a Gonz√°lez y trabajo en la Universidad de Buenos Aires.\n",
        "Vivo en el barrio de San Telmo y mi empresa favorita es MercadoLibre.\n",
        "La semana pasada visit√© el Obelisco con mi amigo Carlos P√©rez,\n",
        "quien trabaja en Google Argentina. Nos encontramos en la estaci√≥n\n",
        "Constituci√≥n del subte y fuimos a comer un asado en La Boca.\n",
        "\"\"\""
      ],
      "id": "test_transformer_ner"
    },
    {
      "cell_type": "code",
      "source": [
        "def analizar_entidades_transformers(texto):\n",
        "    \"\"\"Procesa texto y extrae entidades usando Transformers\"\"\"\n",
        "    if not ner_pipeline:\n",
        "        return []\n",
        "\n",
        "    entidades = ner_pipeline(texto)\n",
        "\n",
        "    # Formatear resultados\n",
        "    resultados = []\n",
        "    for ent in entidades:\n",
        "        resultados.append({\n",
        "            'texto': ent['word'],\n",
        "            'etiqueta': ent['entity_group'],\n",
        "            'confianza': round(ent['score'], 3),\n",
        "            'posicion': (ent['start'], ent['end'])\n",
        "        })\n",
        "\n",
        "    return resultados"
      ],
      "metadata": {
        "id": "v40sR-IKYXyA"
      },
      "id": "v40sR-IKYXyA",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Probar el modelo\n",
        "print(\"üîç Analizando texto de ejemplo...\")\n",
        "print(f\"üìù Texto: {texto_ejemplo.strip()}\")\n",
        "print(\"\\nüìä Entidades encontradas:\")\n",
        "\n",
        "entidades_encontradas = analizar_entidades_transformers(texto_ejemplo)\n",
        "for ent in entidades_encontradas:\n",
        "    print(f\"  ‚Ä¢ {ent['texto']} ‚Üí {ent['etiqueta']} (confianza: {ent['confianza']})\")"
      ],
      "metadata": {
        "id": "lh7rDIQjYXtj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4543602a-0f19-420f-8687-9dafaaa581e3"
      },
      "id": "lh7rDIQjYXtj",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Analizando texto de ejemplo...\n",
            "üìù Texto: Hola, soy Mar√≠a Gonz√°lez y trabajo en la Universidad de Buenos Aires.\n",
            "Vivo en el barrio de San Telmo y mi empresa favorita es MercadoLibre.\n",
            "La semana pasada visit√© el Obelisco con mi amigo Carlos P√©rez,\n",
            "quien trabaja en Google Argentina. Nos encontramos en la estaci√≥n\n",
            "Constituci√≥n del subte y fuimos a comer un asado en La Boca.\n",
            "\n",
            "üìä Entidades encontradas:\n",
            "  ‚Ä¢ Mar√≠a Gonz√°lez ‚Üí PER (confianza: 0.9990000128746033)\n",
            "  ‚Ä¢ Universidad de Buenos Aires ‚Üí ORG (confianza: 0.9990000128746033)\n",
            "  ‚Ä¢ San Telmo ‚Üí LOC (confianza: 0.9980000257492065)\n",
            "  ‚Ä¢ MercadoLibre ‚Üí ORG (confianza: 0.996999979019165)\n",
            "  ‚Ä¢ Obelisco ‚Üí LOC (confianza: 0.9959999918937683)\n",
            "  ‚Ä¢ Carlos P√©rez ‚Üí PER (confianza: 1.0)\n",
            "  ‚Ä¢ Google Argentina ‚Üí ORG (confianza: 0.9860000014305115)\n",
            "  ‚Ä¢ Constituci√≥n ‚Üí LOC (confianza: 0.9950000047683716)\n",
            "  ‚Ä¢ La Boca ‚Üí LOC (confianza: 1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "part2_header"
      },
      "source": [
        "---\n",
        "# PARTE 2: NER con API de Gemini\n",
        "\n",
        "Utilizaremos la API de Gemini para un an√°lisis m√°s detallado y contextual."
      ],
      "id": "part2_header"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "setup_gemini",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "311ab343-c992-41b8-907c-d438e133baad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cliente Gemini configurado correctamente\n"
          ]
        }
      ],
      "source": [
        "# Configurar cliente Gemini\n",
        "cliente_gemini = None\n",
        "\n",
        "if GOOGLE_API_KEY:\n",
        "    try:\n",
        "        from google import genai\n",
        "        cliente_gemini = genai.Client(api_key=GOOGLE_API_KEY)\n",
        "        print(\"Cliente Gemini configurado correctamente\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error al configurar Gemini: {e}\")\n",
        "else:\n",
        "    print(\"API Key de Gemini no disponible\")\n",
        "    print(\"Podes obtener una gratis en: https://ai.google.dev/\")"
      ],
      "id": "setup_gemini"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "test_gemini_ner",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f01c1400-aa5f-4012-d149-5ba45c35d6d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Analizando con Gemini...\n",
            "\n",
            "An√°lisis de Gemini:\n",
            "Aqu√≠ est√°n las entidades nombradas extra√≠das del texto, clasificadas y explicadas:\n",
            "\n",
            "*   Mar√≠a Gonz√°lez ‚Üí PERSONA ‚Üí Nombre de la persona que habla.\n",
            "*   Universidad de Buenos Aires ‚Üí ORGANIZACI√ìN ‚Üí Nombre de una universidad.\n",
            "*   San Telmo ‚Üí LUGAR ‚Üí Nombre de un barrio.\n",
            "*   MercadoLibre ‚Üí ORGANIZACI√ìN ‚Üí Nombre de una empresa.\n",
            "*   Obelisco ‚Üí LUGAR ‚Üí Nombre de un monumento/lugar espec√≠fico.\n",
            "*   Carlos P√©rez ‚Üí PERSONA ‚Üí Nombre del amigo.\n",
            "*   Google Argentina ‚Üí ORGANIZACI√ìN ‚Üí Nombre de una empresa (filial argentina).\n",
            "*   Constituci√≥n ‚Üí LUGAR ‚Üí Nombre de una estaci√≥n de subte (ferrocarril subterr√°neo).\n",
            "*   La Boca ‚Üí LUGAR ‚Üí Nombre de un barrio.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def analizar_entidades_gemini(texto):\n",
        "    \"\"\"Analiza entidades usando Gemini API\"\"\"\n",
        "    if not cliente_gemini:\n",
        "        return \"‚ùå Cliente Gemini no disponible\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Extra√© todas las entidades nombradas del siguiente texto en espa√±ol argentino y clasific√°las:\n",
        "\n",
        "    CATEGOR√çAS:\n",
        "    - PERSONA: Nombres de personas\n",
        "    - LUGAR: Ciudades, pa√≠ses, barrios, direcciones, lugares espec√≠ficos\n",
        "    - ORGANIZACI√ìN: Empresas, universidades, instituciones\n",
        "    - MISCEL√ÅNEO: Otros nombres propios (productos, eventos, marcas)\n",
        "\n",
        "    FORMATO DE RESPUESTA:\n",
        "    [ENTIDAD] ‚Üí [CATEGOR√çA] ‚Üí [BREVE EXPLICACI√ìN]\n",
        "\n",
        "    TEXTO A ANALIZAR:\n",
        "    {texto}\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        respuesta = cliente_gemini.models.generate_content(\n",
        "            model=\"gemini-2.0-flash\",\n",
        "            contents=[prompt]\n",
        "        )\n",
        "        return respuesta.text\n",
        "    except Exception as e:\n",
        "        return f\"‚ùå Error: {e}\"\n",
        "\n",
        "# Probar Gemini si est√° disponible\n",
        "if cliente_gemini:\n",
        "    print(\"üîç Analizando con Gemini...\")\n",
        "    resultado_gemini = analizar_entidades_gemini(texto_ejemplo)\n",
        "    print(\"\\nAn√°lisis de Gemini:\")\n",
        "    print(resultado_gemini)\n",
        "else:\n",
        "    print(\"‚è≠Ô∏è  Saltando an√°lisis con Gemini (API Key no disponible)\")"
      ],
      "id": "test_gemini_ner"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "part3_header"
      },
      "source": [
        "---\n",
        "# PARTE 3: Interfaces Interactivas con Gradio\n",
        "\n",
        "Crearemos interfaces web interactivas para probar nuestros modelos."
      ],
      "id": "part3_header"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "gradio_transformers",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da386f02-2cc7-4ee4-d18a-ef0e82ab78f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Interfaz de Transformers creada\n"
          ]
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "def interfaz_ner_transformers(texto):\n",
        "    \"\"\"Interfaz para el modelo de Transformers\"\"\"\n",
        "    if not texto.strip():\n",
        "        return {\"text\": \"Ingresa un texto para analizar\", \"entities\": []}\n",
        "\n",
        "    if not ner_pipeline:\n",
        "        return {\"text\": \"Modelo no disponible\", \"entities\": []}\n",
        "\n",
        "    # Procesar con Transformers\n",
        "    entidades = ner_pipeline(texto)\n",
        "\n",
        "    # Formatear para Gradio HighlightedText\n",
        "    entidades_gradio = []\n",
        "    for ent in entidades:\n",
        "        entidades_gradio.append({\n",
        "            \"entity\": ent[\"entity_group\"],\n",
        "            \"word\": ent[\"word\"],\n",
        "            \"start\": ent[\"start\"],\n",
        "            \"end\": ent[\"end\"],\n",
        "            \"score\": ent[\"score\"]\n",
        "        })\n",
        "\n",
        "    return {\"text\": texto, \"entities\": entidades_gradio}\n",
        "\n",
        "# Ejemplos para la interfaz\n",
        "ejemplos_arg = [\n",
        "    \"Me llamo Juan P√©rez y trabajo en el Banco Naci√≥n en Buenos Aires.\",\n",
        "    \"Cristina Kirchner fue presidenta de Argentina y vive en Santa Cruz.\",\n",
        "    \"River Plate jugar√° contra Boca Juniors en el estadio Monumental.\",\n",
        "    \"Lionel Messi naci√≥ en Rosario y jug√≥ en el Barcelona.\",\n",
        "    \"La Universidad de La Plata es muy prestigiosa en Argentina.\"\n",
        "]\n",
        "\n",
        "# Crear interfaz\n",
        "demo_transformers = gr.Interface(\n",
        "    fn=interfaz_ner_transformers,\n",
        "    inputs=[\n",
        "        gr.Textbox(\n",
        "            label=\"üìù Texto a analizar\",\n",
        "            placeholder=\"Escribe aqu√≠ tu texto en espa√±ol...\",\n",
        "            lines=4\n",
        "        )\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.HighlightedText(\n",
        "            label=\"üéØ Entidades Identificadas\",\n",
        "            show_legend=True\n",
        "        )\n",
        "    ],\n",
        "    title=\"NER con Transformers - Espa√±ol (de argentina)\",\n",
        "    description=\"\"\"\n",
        "    **Modelo:** `mrm8488/bert-spanish-cased-finetuned-ner`\n",
        "\n",
        "    Identifica entidades nombradas en textos en espa√±ol:\n",
        "    - üßë **PER**: Personas\n",
        "    - üåç **LOC**: Lugares\n",
        "    - üè¢ **ORG**: Organizaciones\n",
        "    - üì¶ **MISC**: Miscel√°neo\n",
        "    \"\"\",\n",
        "    examples=ejemplos_arg,\n",
        "    allow_flagging=\"never\",\n",
        "    theme=gr.themes.Soft()\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Interfaz de Transformers creada\")"
      ],
      "id": "gradio_transformers"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "gradio_gemini",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8b58755-9809-43c1-d09f-317a6f1e7eca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Interfaz de Gemini creada\n"
          ]
        }
      ],
      "source": [
        "# Interfaz para Gemini (solo si est√° disponible)\n",
        "if cliente_gemini:\n",
        "    def interfaz_ner_gemini(texto):\n",
        "        \"\"\"Interfaz para Gemini API\"\"\"\n",
        "        if not texto.strip():\n",
        "            return \"Ingresa un texto para analizar\"\n",
        "        return analizar_entidades_gemini(texto)\n",
        "\n",
        "    demo_gemini = gr.Interface(\n",
        "        fn=interfaz_ner_gemini,\n",
        "        inputs=[\n",
        "            gr.Textbox(\n",
        "                label=\"üìù Texto a analizar\",\n",
        "                placeholder=\"Escribe aqu√≠ tu texto en espa√±ol...\",\n",
        "                lines=4\n",
        "            )\n",
        "        ],\n",
        "        outputs=[\n",
        "            gr.Textbox(\n",
        "                label=\"üß† An√°lisis de Gemini\",\n",
        "                lines=10\n",
        "            )\n",
        "        ],\n",
        "        title=\"NER con Gemini - An√°lisis Detallado\",\n",
        "        description=\"\"\"\n",
        "        **Modelo:** Google Gemini 2.0 Flash\n",
        "\n",
        "        An√°lisis avanzado de entidades nombradas con explicaciones contextuales\n",
        "        optimizado para espa√±ol argentino.\n",
        "        \"\"\",\n",
        "        examples=ejemplos_arg,\n",
        "        allow_flagging=\"never\",\n",
        "        theme=gr.themes.Soft()\n",
        "    )\n",
        "    print(\"‚úÖ Interfaz de Gemini creada\")\n",
        "else:\n",
        "    print(\"‚è≠Ô∏è  Interfaz de Gemini no creada (API Key no disponible)\")"
      ],
      "id": "gradio_gemini"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "gradio_comparison",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca4d8713-b657-4409-ce5c-9e1694eab567"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Interfaz comparativa creada\n"
          ]
        }
      ],
      "source": [
        "# Interfaz comparativa (solo si ambos est√°n disponibles)\n",
        "if ner_pipeline and cliente_gemini:\n",
        "    def comparar_modelos(texto):\n",
        "        \"\"\"Compara resultados de ambos modelos\"\"\"\n",
        "        if not texto.strip():\n",
        "            return \"Ingresa texto para comparar\", \"Ingresa texto para comparar\"\n",
        "\n",
        "        # Resultado Transformers\n",
        "        entidades_tf = analizar_entidades_transformers(texto)\n",
        "        resultado_tf = \"TRANSFORMERS:\\n\\n\"\n",
        "        for ent in entidades_tf:\n",
        "            resultado_tf += f\"‚Ä¢ {ent['texto']} ‚Üí {ent['etiqueta']} (confianza: {ent['confianza']})\\n\"\n",
        "\n",
        "        # Resultado Gemini\n",
        "        resultado_gemini = \"GEMINI:\\n\\n\" + analizar_entidades_gemini(texto)\n",
        "\n",
        "        return resultado_tf, resultado_gemini\n",
        "\n",
        "    demo_comparativo = gr.Interface(\n",
        "        fn=comparar_modelos,\n",
        "        inputs=[\n",
        "            gr.Textbox(\n",
        "                label=\"üìù Texto a comparar\",\n",
        "                placeholder=\"Ingresa texto para ver la comparaci√≥n...\",\n",
        "                lines=3\n",
        "            )\n",
        "        ],\n",
        "        outputs=[\n",
        "            gr.Textbox(label=\"Transformers\", lines=8),\n",
        "            gr.Textbox(label=\"Gemini\", lines=8)\n",
        "        ],\n",
        "        title=\"‚öîÔ∏è Comparaci√≥n: Transformers vs Gemini\",\n",
        "        description=\"Compara los resultados de ambos enfoques lado a lado.\",\n",
        "        examples=[\n",
        "            \"Diego Maradona jug√≥ en Boca Juniors y en el Napoli de Italia.\",\n",
        "            \"El gobierno argentino anunci√≥ medidas desde Casa Rosada.\"\n",
        "        ],\n",
        "        allow_flagging=\"never\"\n",
        "    )\n",
        "    print(\"‚úÖ Interfaz comparativa creada\")\n",
        "else:\n",
        "    print(\"‚è≠Ô∏è  Interfaz comparativa no creada (requiere ambos modelos)\")"
      ],
      "id": "gradio_comparison"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "launch_section"
      },
      "source": [
        "## üöÄ Lanzar Interfaces\n",
        "\n",
        "Ejecuta las celdas siguientes para lanzar las interfaces interactivas:"
      ],
      "id": "launch_section"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "launch_transformers",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "outputId": "0c06855f-f387-40e0-8ea2-83ae6e4c58cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Lanzando interfaz de Transformers...\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://a2af462efeb862fc90.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://a2af462efeb862fc90.gradio.live\" width=\"100%\" height=\"600\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Lanzar interfaz de Transformers\n",
        "if ner_pipeline:\n",
        "    print(\"üöÄ Lanzando interfaz de Transformers...\")\n",
        "    demo_transformers.launch(share=True, height=600)\n",
        "else:\n",
        "    print(\"‚ùå No se puede lanzar: modelo de Transformers no disponible\")"
      ],
      "id": "launch_transformers"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "launch_gemini",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "outputId": "0a18e2c3-2b83-49de-e901-e5a8662d3bdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Lanzando interfaz de Gemini...\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://bce8391c4ecfc9b0b0.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://bce8391c4ecfc9b0b0.gradio.live\" width=\"100%\" height=\"600\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Lanzar interfaz de Gemini\n",
        "if cliente_gemini:\n",
        "    print(\"üöÄ Lanzando interfaz de Gemini...\")\n",
        "    demo_gemini.launch(share=True, height=600)\n",
        "else:\n",
        "    print(\"‚ùå No se puede lanzar: API de Gemini no disponible\")"
      ],
      "id": "launch_gemini"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "launch_comparison",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "outputId": "81382ace-34b8-4c3b-f4cd-fb391db6550f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Lanzando interfaz comparativa...\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://8ed6bebcdbef5e1fc7.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://8ed6bebcdbef5e1fc7.gradio.live\" width=\"100%\" height=\"600\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Lanzar interfaz comparativa\n",
        "if ner_pipeline and cliente_gemini:\n",
        "    print(\"üöÄ Lanzando interfaz comparativa...\")\n",
        "    demo_comparativo.launch(share=True, height=600)\n",
        "else:\n",
        "    print(\"‚ùå No se puede lanzar: requiere ambos modelos disponibles\")"
      ],
      "id": "launch_comparison"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exercises_section"
      },
      "source": [
        "---\n",
        "# üéì EJERCICIOS\n",
        "\n",
        "## üìù Ejercicio 1: Personalizaci√≥n (B√ÅSICO)\n",
        "1. Modifica los ejemplos para incluir m√°s contexto argentino espec√≠fico\n",
        "2. Agrega 3 ejemplos nuevos con nombres de barrios porte√±os\n",
        "3. Prob√° con texto de diferentes regiones de Argentina\n",
        "\n",
        "## üîß Ejercicio 2: An√°lisis Comparativo (INTERMEDIO)\n",
        "1. Crea una funci√≥n que cuente cu√°ntas entidades encuentra cada modelo\n",
        "2. Implementa un sistema de m√©tricas de tiempo de procesamiento\n",
        "3. Analiza en qu√© casos cada modelo funciona mejor\n",
        "\n",
        "## üöÄ Ejercicio 3: Extensiones Avanzadas (AVANZADO)\n",
        "1. Implementa procesamiento en lote de m√∫ltiples textos\n",
        "2. Crea una funci√≥n de exportaci√≥n de resultados a CSV\n",
        "3. Desarrolla un sistema de filtrado por tipo de entidad\n",
        "\n",
        "## üí° Proyecto Integrador\n",
        "Eleg√≠ una de estas aplicaciones y desarr√≥llala:\n",
        "- **Analizador de noticias argentinas**: Extrae personas y lugares de art√≠culos\n",
        "- **Procesador de CVs**: Identifica nombres, empresas y universidades\n",
        "- **An√°lisis de redes sociales**: Detecta menciones de pol√≠ticos y lugares\n",
        "\n",
        "## ü§î Preguntas de Reflexi√≥n\n",
        "1. ¬øCu√°les son las ventajas y desventajas de cada enfoque?\n",
        "2. ¬øEn qu√© casos usar√≠as un modelo local vs una API?\n",
        "3. ¬øC√≥mo evaluar√≠as la precisi√≥n de los resultados?\n",
        "4. ¬øQu√© consideraciones √©ticas debemos tener en cuenta?\n",
        "5. ¬øC√≥mo escalar√≠as esta soluci√≥n para procesar miles de documentos?"
      ],
      "id": "exercises_section"
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr # Importa la librer√≠a Gradio.\n",
        "\n",
        "def interfaz_ner_transformers(texto):\n",
        "    \"\"\"\n",
        "    Funci√≥n de envoltorio para la interfaz de Gradio del modelo Transformers.\n",
        "    Formatea la salida para ser compatible con gr.HighlightedText.\n",
        "    \"\"\"\n",
        "    if not texto.strip(): # Verifica si el texto de entrada est√° vac√≠o.\n",
        "        return {\"text\": \"Ingresa un texto para analizar\", \"entities\": []} # Retorna mensaje si est√° vac√≠o.\n",
        "\n",
        "    if not ner_pipeline: # Verifica si el pipeline de Transformers est√° disponible.\n",
        "        return {\"text\": \"Modelo no disponible\", \"entities\": []} # Retorna mensaje si no lo est√°.\n",
        "\n",
        "    # Procesa el texto con el pipeline de Transformers.\n",
        "    entidades = ner_pipeline(texto)\n",
        "\n",
        "    # Formatea los resultados para el componente HighlightedText de Gradio.\n",
        "    entidades_gradio = []\n",
        "    for ent in entidades:\n",
        "        entidades_gradio.append({\n",
        "            \"entity\": ent[\"entity_group\"], # La etiqueta de la entidad.\n",
        "            \"word\": ent[\"word\"],         # La palabra o frase de la entidad.\n",
        "            \"start\": ent[\"start\"],       # Posici√≥n de inicio en el texto.\n",
        "            \"end\": ent[\"end\"],           # Posici√≥n de fin en el texto.\n",
        "            \"score\": ent[\"score\"]        # Puntuaci√≥n de confianza.\n",
        "        })\n",
        "\n",
        "    return {\"text\": texto, \"entities\": entidades_gradio} # Retorna el texto original y las entidades formateadas.\n",
        "\n",
        "# Ejemplos para la interfaz de Gradio, con contexto argentino.\n",
        "ejemplos_arg = [\n",
        "    \"Me llamo Juan P√©rez y trabajo en el Banco Naci√≥n en Buenos Aires.\",\n",
        "    \"Cristina Kirchner fue presidenta de Argentina y vive en Santa Cruz.\",\n",
        "    \"River Plate jugar√° contra Boca Juniors en el estadio Monumental.\",\n",
        "    \"Lionel Messi naci√≥ en Rosario y jug√≥ en el Barcelona.\",\n",
        "    \"La Universidad de La Plata es muy prestigiosa en Argentina.\",\n",
        "    # --- Ejercicio 1: Ejemplos nuevos con barrios porte√±os ---\n",
        "    \"El barrio de Palermo es famoso por sus parques y vida nocturna.\",\n",
        "    \"Recoleta tiene edificios hist√≥ricos y el Cementerio de la Recoleta.\",\n",
        "    \"En Boedo se respira el tango y la tradici√≥n barrial.\"\n",
        "]\n",
        "\n",
        "# --- Interfaz para Transformers ---\n",
        "demo_transformers = gr.Interface(\n",
        "    fn=interfaz_ner_transformers, # La funci√≥n que procesa la entrada.\n",
        "    inputs=[\n",
        "        gr.Textbox(\n",
        "            label=\"üìù Texto a analizar\",\n",
        "            placeholder=\"Escribe aqu√≠ tu texto en espa√±ol...\",\n",
        "            lines=4\n",
        "        )\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.HighlightedText( # Componente de Gradio que resalta entidades en el texto.\n",
        "            label=\"üéØ Entidades Identificadas\",\n",
        "            show_legend=True # Muestra la leyenda de las etiquetas.\n",
        "        )\n",
        "    ],\n",
        "    title=\"NER con Transformers - Espa√±ol (de Argentina)\", # T√≠tulo de la interfaz.\n",
        "    description=\"\"\"\n",
        "    **Modelo:** `mrm8488/bert-spanish-cased-finetuned-ner`\n",
        "\n",
        "    Identifica entidades nombradas en textos en espa√±ol:\n",
        "    - üßë **PER**: Personas\n",
        "    - üåç **LOC**: Lugares\n",
        "    - üè¢ **ORG**: Organizaciones\n",
        "    - üì¶ **MISC**: Miscel√°neo\n",
        "    \"\"\",\n",
        "    examples=ejemplos_arg, # Ejemplos predefinidos.\n",
        "    allow_flagging=\"never\", # Deshabilita la opci√≥n de \"flagging\".\n",
        "    theme=gr.themes.Soft() # Aplica un tema visual.\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Interfaz de Transformers creada\")\n",
        "\n",
        "# --- Interfaz para Gemini (solo si est√° disponible) ---\n",
        "if cliente_gemini: # Solo se crea si la API Key de Gemini est√° configurada.\n",
        "    def interfaz_ner_gemini(texto):\n",
        "        \"\"\"\n",
        "        Funci√≥n de envoltorio para la interfaz de Gradio del modelo Gemini.\n",
        "        \"\"\"\n",
        "        if not texto.strip():\n",
        "            return \"Ingresa un texto para analizar\"\n",
        "        return analizar_entidades_gemini(texto) # Llama a la funci√≥n de an√°lisis con Gemini.\n",
        "\n",
        "    demo_gemini = gr.Interface(\n",
        "        fn=interfaz_ner_gemini,\n",
        "        inputs=[\n",
        "            gr.Textbox(\n",
        "                label=\"üìù Texto a analizar\",\n",
        "                placeholder=\"Escribe aqu√≠ tu texto en espa√±ol...\",\n",
        "                lines=4\n",
        "            )\n",
        "        ],\n",
        "        outputs=[\n",
        "            gr.Textbox( # Gemini retorna un texto plano con las entidades.\n",
        "                label=\"üß† An√°lisis de Gemini\",\n",
        "                lines=10\n",
        "            )\n",
        "        ],\n",
        "        title=\"NER con Gemini - An√°lisis Detallado\",\n",
        "        description=\"\"\"\n",
        "        **Modelo:** Google Gemini 2.0 Flash\n",
        "\n",
        "        An√°lisis avanzado de entidades nombradas con explicaciones contextuales\n",
        "        optimizado para espa√±ol argentino.\n",
        "        \"\"\",\n",
        "        examples=ejemplos_arg,\n",
        "        allow_flagging=\"never\",\n",
        "        theme=gr.themes.Soft()\n",
        "    )\n",
        "    print(\"‚úÖ Interfaz de Gemini creada\")\n",
        "else:\n",
        "    print(\"‚è≠Ô∏è  Interfaz de Gemini no creada (API Key no disponible)\")\n",
        "\n",
        "# --- Interfaz comparativa (solo si ambos est√°n disponibles) ---\n",
        "if ner_pipeline and cliente_gemini: # Solo se crea si ambos modelos est√°n cargados.\n",
        "    def comparar_modelos(texto):\n",
        "        \"\"\"\n",
        "        Funci√≥n para comparar los resultados de NER de ambos modelos lado a lado.\n",
        "        \"\"\"\n",
        "        if not texto.strip():\n",
        "            return \"Ingresa texto para comparar\", \"Ingresa texto para comparar\"\n",
        "\n",
        "        # Formatea el resultado de Transformers para visualizaci√≥n de texto plano.\n",
        "        entidades_tf = analizar_entidades_transformers(texto)\n",
        "        resultado_tf = \"TRANSFORMERS:\\n\\n\"\n",
        "        for ent in entidades_tf:\n",
        "            resultado_tf += f\"‚Ä¢ {ent['texto']} ‚Üí {ent['etiqueta']} (confianza: {ent['confianza']})\\n\"\n",
        "\n",
        "        # Obtiene el resultado de Gemini.\n",
        "        resultado_gemini = \"GEMINI:\\n\\n\" + analizar_entidades_gemini(texto)\n",
        "\n",
        "        return resultado_tf, resultado_gemini # Retorna ambos resultados.\n",
        "\n",
        "    demo_comparativo = gr.Interface(\n",
        "        fn=comparar_modelos,\n",
        "        inputs=[\n",
        "            gr.Textbox(\n",
        "                label=\"üìù Texto a comparar\",\n",
        "                placeholder=\"Ingresa texto para ver la comparaci√≥n...\",\n",
        "                lines=3\n",
        "            )\n",
        "        ],\n",
        "        outputs=[\n",
        "            gr.Textbox(label=\"Transformers\", lines=8),\n",
        "            gr.Textbox(label=\"Gemini\", lines=8)\n",
        "        ],\n",
        "        title=\"‚öîÔ∏è Comparaci√≥n: Transformers vs Gemini\",\n",
        "        description=\"Compara los resultados de ambos enfoques lado a lado.\",\n",
        "        examples=[\n",
        "            \"Diego Maradona jug√≥ en Boca Juniors y en el Napoli de Italia.\",\n",
        "            \"El gobierno argentino anunci√≥ medidas desde Casa Rosada.\"\n",
        "        ],\n",
        "        allow_flagging=\"never\"\n",
        "    )\n",
        "    print(\"‚úÖ Interfaz comparativa creada\")\n",
        "else:\n",
        "    print(\"‚è≠Ô∏è  Interfaz comparativa no creada (requiere ambos modelos)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVa01zuHT8Ri",
        "outputId": "2041548b-1fb7-4efd-9821-0732f78b8e9a"
      },
      "id": "uVa01zuHT8Ri",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Interfaz de Transformers creada\n",
            "‚úÖ Interfaz de Gemini creada\n",
            "‚úÖ Interfaz comparativa creada\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lanzar interfaz comparativa\n",
        "if ner_pipeline and cliente_gemini:\n",
        "    print(\"üöÄ Lanzando interfaz comparativa...\")\n",
        "    demo_comparativo.launch(share=True, height=600)\n",
        "else:\n",
        "    print(\"‚ùå No se puede lanzar: requiere ambos modelos disponibles\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "id": "LGrm8TDYUfEO",
        "outputId": "e741c7a4-d5fd-4b9f-fdee-32fa7c1eeb43"
      },
      "id": "LGrm8TDYUfEO",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Lanzando interfaz comparativa...\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://9a317f13436259d99d.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://9a317f13436259d99d.gradio.live\" width=\"100%\" height=\"600\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejercicio 2)"
      ],
      "metadata": {
        "id": "-LCreK_9TuoH"
      },
      "id": "-LCreK_9TuoH"
    },
    {
      "cell_type": "code",
      "source": [
        "import time # Importar el m√≥dulo time para medir el tiempo de ejecuci√≥n.\n",
        "\n",
        "print(\"\\n--- EJERCICIO 2: An√°lisis Comparativo ---\")\n",
        "\n",
        "def contar_y_medir_entidades(texto):\n",
        "    \"\"\"\n",
        "    Cuenta el n√∫mero de entidades y mide el tiempo de procesamiento para cada modelo.\n",
        "    \"\"\"\n",
        "    resultados_comparativos = {}\n",
        "\n",
        "    # --- Transformers ---\n",
        "    start_time_tf = time.time() # Inicia el cron√≥metro para Transformers.\n",
        "    entidades_tf = analizar_entidades_transformers(texto)\n",
        "    end_time_tf = time.time() # Detiene el cron√≥metro.\n",
        "    tiempo_tf = end_time_tf - start_time_tf\n",
        "    num_entidades_tf = len(entidades_tf)\n",
        "\n",
        "    resultados_comparativos['transformers'] = {\n",
        "        'num_entidades': num_entidades_tf,\n",
        "        'tiempo_ms': round(tiempo_tf * 1000, 2), # Convierte a milisegundos.\n",
        "        'entidades': entidades_tf # Guarda las entidades para an√°lisis posterior.\n",
        "    }\n",
        "\n",
        "    # --- Gemini ---\n",
        "    if cliente_gemini:\n",
        "        start_time_gemini = time.time() # Inicia el cron√≥metro para Gemini.\n",
        "        raw_gemini_output = analizar_entidades_gemini(texto)\n",
        "        end_time_gemini = time.time() # Detiene el cron√≥metro.\n",
        "        tiempo_gemini = end_time_gemini - start_time_gemini\n",
        "\n",
        "        # Intentar contar entidades de Gemini (depende del formato de salida)\n",
        "        # Esto es una aproximaci√≥n, asumiendo una entidad por l√≠nea.\n",
        "        num_entidades_gemini = len([line for line in raw_gemini_output.split('\\n') if '‚Üí' in line])\n",
        "\n",
        "        resultados_comparativos['gemini'] = {\n",
        "            'num_entidades': num_entidades_gemini,\n",
        "            'tiempo_ms': round(tiempo_gemini * 1000, 2),\n",
        "            'raw_output': raw_gemini_output # Guarda la salida cruda para an√°lisis.\n",
        "        }\n",
        "    else:\n",
        "        resultados_comparativos['gemini'] = {\n",
        "            'num_entidades': \"N/A\",\n",
        "            'tiempo_ms': \"N/A\",\n",
        "            'raw_output': \"Cliente Gemini no disponible\"\n",
        "        }\n",
        "\n",
        "    return resultados_comparativos\n",
        "\n",
        "# --- Pruebas para el An√°lisis Comparativo ---\n",
        "texto_prueba_1 = \"El Dr. Facundo Manes visit√≥ la Facultad de Medicina de la UBA en Recoleta.\"\n",
        "texto_prueba_2 = \"La empresa Tech Solutions Inc. inaugur√≥ su nueva sede en el Polo Tecnol√≥gico de la Ciudad de C√≥rdoba.\"\n",
        "texto_prueba_3 = \"Lionel Messi gan√≥ su octavo Bal√≥n de Oro en 2023. Juega para Inter Miami.\"\n",
        "\n",
        "print(f\"\\n--- Analizando: '{texto_prueba_1}' ---\")\n",
        "comp_1 = contar_y_medir_entidades(texto_prueba_1)\n",
        "print(f\"  Transformers: {comp_1['transformers']['num_entidades']} entidades en {comp_1['transformers']['tiempo_ms']} ms\")\n",
        "print(f\"  Gemini: {comp_1['gemini']['num_entidades']} entidades en {comp_1['gemini']['tiempo_ms']} ms\")\n",
        "print(f\"  Entidades Transformers: {[ent['texto'] for ent in comp_1['transformers']['entidades']]}\")\n",
        "print(f\"  Salida Gemini: \\n{comp_1['gemini']['raw_output']}\")\n",
        "\n",
        "print(f\"\\n--- Analizando: '{texto_prueba_2}' ---\")\n",
        "comp_2 = contar_y_medir_entidades(texto_prueba_2)\n",
        "print(f\"  Transformers: {comp_2['transformers']['num_entidades']} entidades en {comp_2['transformers']['tiempo_ms']} ms\")\n",
        "print(f\"  Gemini: {comp_2['gemini']['num_entidades']} entidades en {comp_2['gemini']['tiempo_ms']} ms\")\n",
        "print(f\"  Entidades Transformers: {[ent['texto'] for ent in comp_2['transformers']['entidades']]}\")\n",
        "print(f\"  Salida Gemini: \\n{comp_2['gemini']['raw_output']}\")\n",
        "\n",
        "print(f\"\\n--- Analizando: '{texto_prueba_3}' ---\")\n",
        "comp_3 = contar_y_medir_entidades(texto_prueba_3)\n",
        "print(f\"  Transformers: {comp_3['transformers']['num_entidades']} entidades en {comp_3['transformers']['tiempo_ms']} ms\")\n",
        "print(f\"  Gemini: {comp_3['gemini']['num_entidades']} entidades en {comp_3['gemini']['tiempo_ms']} ms\")\n",
        "print(f\"  Entidades Transformers: {[ent['texto'] for ent in comp_3['transformers']['entidades']]}\")\n",
        "print(f\"  Salida Gemini: \\n{comp_3['gemini']['raw_output']}\")\n",
        "\n",
        "print(\"\\n--- An√°lisis de Rendimiento y Casos (Ejercicio 2) ---\")\n",
        "print(\"Observaciones de las pruebas:\")\n",
        "print(\"- **Rendimiento (Tiempo)**: Generalmente, el modelo local de Transformers (si usa GPU) es **m√°s r√°pido** que la llamada a la API de Gemini, que implica latencia de red. Para procesamiento en tiempo real o de alto volumen, Transformers es usualmente preferible.\")\n",
        "print(\"- **Cobertura y Precisi√≥n**: \")\n",
        "print(\"  - **Transformers**: Excelente para las categor√≠as est√°ndar (PER, LOC, ORG). Puede ser muy preciso en entidades conocidas si fueron vistas en su entrenamiento.\")\n",
        "print(\"  - **Gemini**: Su fuerza radica en la **flexibilidad y contextualizaci√≥n**. Puede identificar entidades 'MISC' de forma m√°s robusta o incluso entidades que no encajan perfectamente en las categor√≠as predefinidas de un modelo NER tradicional. Adem√°s, su explicaci√≥n ('BREVE EXPLICACI√ìN') es un valor agregado.\")\n",
        "print(\"  - **Casos de mejora**: En textos con lenguaje coloquial, neologismos o entidades muy espec√≠ficas/nuevas que no est√©n en el dataset de entrenamiento del modelo de Transformers, Gemini (como LLM) podr√≠a tener una mejor capacidad de inferencia debido a su conocimiento general del mundo.\")\n",
        "print(\"  - **Inconsistencias**: Transformers puede a veces dividir entidades multi-palabra de forma incorrecta si `aggregation_strategy` no es perfecto o el modelo no fue entrenado para ese patr√≥n espec√≠fico. Gemini, al ser generativo, puede a veces 'inventar' una explicaci√≥n o clasificar de forma inesperada si el prompt no es lo suficientemente restrictivo o el contexto es ambiguo.\")\n",
        "print(\"-\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QS2uBe-hTBqb",
        "outputId": "01b0a837-5e97-470f-b331-55f2404af08b"
      },
      "id": "QS2uBe-hTBqb",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- EJERCICIO 2: An√°lisis Comparativo ---\n",
            "\n",
            "--- Analizando: 'El Dr. Facundo Manes visit√≥ la Facultad de Medicina de la UBA en Recoleta.' ---\n",
            "  Transformers: 5 entidades en 270.66 ms\n",
            "  Gemini: 4 entidades en 1107.98 ms\n",
            "  Entidades Transformers: ['Dr', '. Facundo Manes', 'Facultad de Medicina', 'UBA', 'Recoleta']\n",
            "  Salida Gemini: \n",
            "*   Dr. Facundo Manes ‚Üí PERSONA ‚Üí Nombre de una persona, precedido por un t√≠tulo (Dr.).\n",
            "*   Facultad de Medicina ‚Üí ORGANIZACI√ìN ‚Üí Nombre de una facultad.\n",
            "*   UBA ‚Üí ORGANIZACI√ìN ‚Üí Siglas de la Universidad de Buenos Aires.\n",
            "*   Recoleta ‚Üí LUGAR ‚Üí Nombre de un barrio en Buenos Aires.\n",
            "\n",
            "\n",
            "--- Analizando: 'La empresa Tech Solutions Inc. inaugur√≥ su nueva sede en el Polo Tecnol√≥gico de la Ciudad de C√≥rdoba.' ---\n",
            "  Transformers: 2 entidades en 215.49 ms\n",
            "  Gemini: 3 entidades en 644.09 ms\n",
            "  Entidades Transformers: ['Tech Solutions Inc.', 'Polo Tecnol√≥gico de la Ciudad de C√≥rdoba']\n",
            "  Salida Gemini: \n",
            "*   Tech Solutions Inc. ‚Üí ORGANIZACI√ìN ‚Üí Nombre de la empresa\n",
            "*   Polo Tecnol√≥gico ‚Üí LUGAR ‚Üí Nombre espec√≠fico de una zona\n",
            "*   Ciudad de C√≥rdoba ‚Üí LUGAR ‚Üí Ciudad en Argentina\n",
            "\n",
            "\n",
            "--- Analizando: 'Lionel Messi gan√≥ su octavo Bal√≥n de Oro en 2023. Juega para Inter Miami.' ---\n",
            "  Transformers: 3 entidades en 142.83 ms\n",
            "  Gemini: 4 entidades en 702.69 ms\n",
            "  Entidades Transformers: ['Lionel Messi', 'Bal√≥n de Oro', 'Inter Miami']\n",
            "  Salida Gemini: \n",
            "*   Lionel Messi ‚Üí PERSONA ‚Üí Nombre del futbolista.\n",
            "*   Bal√≥n de Oro ‚Üí MISCEL√ÅNEO ‚Üí Nombre del premio.\n",
            "*   2023 ‚Üí MISCEL√ÅNEO ‚Üí A√±o.\n",
            "*   Inter Miami ‚Üí ORGANIZACI√ìN ‚Üí Nombre del club de f√∫tbol.\n",
            "\n",
            "\n",
            "--- An√°lisis de Rendimiento y Casos (Ejercicio 2) ---\n",
            "Observaciones de las pruebas:\n",
            "- **Rendimiento (Tiempo)**: Generalmente, el modelo local de Transformers (si usa GPU) es **m√°s r√°pido** que la llamada a la API de Gemini, que implica latencia de red. Para procesamiento en tiempo real o de alto volumen, Transformers es usualmente preferible.\n",
            "- **Cobertura y Precisi√≥n**: \n",
            "  - **Transformers**: Excelente para las categor√≠as est√°ndar (PER, LOC, ORG). Puede ser muy preciso en entidades conocidas si fueron vistas en su entrenamiento.\n",
            "  - **Gemini**: Su fuerza radica en la **flexibilidad y contextualizaci√≥n**. Puede identificar entidades 'MISC' de forma m√°s robusta o incluso entidades que no encajan perfectamente en las categor√≠as predefinidas de un modelo NER tradicional. Adem√°s, su explicaci√≥n ('BREVE EXPLICACI√ìN') es un valor agregado.\n",
            "  - **Casos de mejora**: En textos con lenguaje coloquial, neologismos o entidades muy espec√≠ficas/nuevas que no est√©n en el dataset de entrenamiento del modelo de Transformers, Gemini (como LLM) podr√≠a tener una mejor capacidad de inferencia debido a su conocimiento general del mundo.\n",
            "  - **Inconsistencias**: Transformers puede a veces dividir entidades multi-palabra de forma incorrecta si `aggregation_strategy` no es perfecto o el modelo no fue entrenado para ese patr√≥n espec√≠fico. Gemini, al ser generativo, puede a veces 'inventar' una explicaci√≥n o clasificar de forma inesperada si el prompt no es lo suficientemente restrictivo o el contexto es ambiguo.\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejercicio 3"
      ],
      "metadata": {
        "id": "8LZaCTboTiJT"
      },
      "id": "8LZaCTboTiJT"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd # Importar pandas para exportar a CSV y manipulaci√≥n de datos.\n",
        "\n",
        "print(\"\\n--- EJERCICIO 3: Extensiones Avanzadas ---\")\n",
        "\n",
        "# --- 3.1 Procesamiento en Lote ---\n",
        "def procesar_lote_transformers(lista_textos):\n",
        "    \"\"\"\n",
        "    Procesa una lista de textos con el pipeline de Transformers.\n",
        "    \"\"\"\n",
        "    if not ner_pipeline:\n",
        "        return []\n",
        "\n",
        "    print(f\"Procesando {len(lista_textos)} textos con Transformers...\")\n",
        "    resultados_lote = []\n",
        "    for i, texto in enumerate(lista_textos):\n",
        "        entidades = analizar_entidades_transformers(texto)\n",
        "        resultados_lote.append({'id_texto': i, 'texto_original': texto, 'entidades': entidades})\n",
        "    return resultados_lote\n",
        "\n",
        "def procesar_lote_gemini(lista_textos):\n",
        "    \"\"\"\n",
        "    Procesa una lista de textos con Gemini.\n",
        "    \"\"\"\n",
        "    if not cliente_gemini:\n",
        "        return []\n",
        "\n",
        "    print(f\"Procesando {len(lista_textos)} textos con Gemini...\")\n",
        "    resultados_lote = []\n",
        "    for i, texto in enumerate(lista_textos):\n",
        "        respuesta_gemini = analizar_entidades_gemini(texto)\n",
        "        resultados_lote.append({'id_texto': i, 'texto_original': texto, 'gemini_raw_output': respuesta_gemini})\n",
        "    return resultados_lote\n",
        "\n",
        "# Ejemplo de uso en lote\n",
        "textos_para_lote = [\n",
        "    \"Juan trabaja en Aerol√≠neas Argentinas y vive en Caballito.\",\n",
        "    \"El Museo Nacional de Bellas Artes est√° en Recoleta, Buenos Aires.\",\n",
        "    \"La AFA organiz√≥ un torneo en el predio de Ezeiza.\",\n",
        "    \"Mercedes Sosa fue una cantante folcl√≥rica de Tucum√°n.\"\n",
        "]\n",
        "\n",
        "print(\"\\n--- Procesamiento en Lote (Transformers) ---\")\n",
        "lote_transformers = procesar_lote_transformers(textos_para_lote)\n",
        "for res in lote_transformers:\n",
        "    print(f\"Texto ID {res['id_texto']}: {len(res['entidades'])} entidades\")\n",
        "    # print(res['entidades']) # Descomentar para ver todas las entidades\n",
        "\n",
        "if cliente_gemini:\n",
        "    print(\"\\n--- Procesamiento en Lote (Gemini) ---\")\n",
        "    lote_gemini = procesar_lote_gemini(textos_para_lote)\n",
        "    for res in lote_gemini:\n",
        "        print(f\"Texto ID {res['id_texto']}: \\n{res['gemini_raw_output']}\\n---\")\n",
        "\n",
        "# --- 3.2 Funci√≥n de Exportaci√≥n a CSV ---\n",
        "def exportar_a_csv_transformers(resultados_lote_transformers, nombre_archivo=\"entidades_transformers.csv\"):\n",
        "    \"\"\"\n",
        "    Exporta los resultados de NER de Transformers a un archivo CSV.\n",
        "    Cada fila representa una entidad.\n",
        "    \"\"\"\n",
        "    registros = []\n",
        "    for res_texto in resultados_lote_transformers:\n",
        "        for ent in res_texto['entidades']:\n",
        "            registros.append({\n",
        "                'id_texto': res_texto['id_texto'],\n",
        "                'texto_original': res_texto['texto_original'],\n",
        "                'entidad_texto': ent['texto'],\n",
        "                'etiqueta': ent['etiqueta'],\n",
        "                'confianza': ent['confianza'],\n",
        "                'posicion_inicio': ent['posicion'][0],\n",
        "                'posicion_fin': ent['posicion'][1]\n",
        "            })\n",
        "\n",
        "    df = pd.DataFrame(registros)\n",
        "    df.to_csv(nombre_archivo, index=False)\n",
        "    print(f\"Resultados de Transformers exportados a '{nombre_archivo}'\")\n",
        "\n",
        "def exportar_a_csv_gemini(resultados_lote_gemini, nombre_archivo=\"entidades_gemini.csv\"):\n",
        "    \"\"\"\n",
        "    Exporta los resultados crudos de Gemini a un archivo CSV.\n",
        "    Cada fila es la salida completa de Gemini para un texto.\n",
        "    \"\"\"\n",
        "    registros = []\n",
        "    for res_texto in resultados_lote_gemini:\n",
        "        registros.append({\n",
        "            'id_texto': res_texto['id_texto'],\n",
        "            'texto_original': res_texto['texto_original'],\n",
        "            'gemini_raw_output': res_texto['gemini_raw_output']\n",
        "        })\n",
        "    df = pd.DataFrame(registros)\n",
        "    df.to_csv(nombre_archivo, index=False)\n",
        "    print(f\"Resultados de Gemini (salida raw) exportados a '{nombre_archivo}'\")\n",
        "\n",
        "print(\"\\n--- Exportando resultados a CSV ---\")\n",
        "exportar_a_csv_transformers(lote_transformers)\n",
        "if cliente_gemini:\n",
        "    exportar_a_csv_gemini(lote_gemini)\n",
        "\n",
        "# --- 3.3 Sistema de Filtrado por Tipo de Entidad ---\n",
        "def filtrar_entidades_transformers(entidades, tipo_entidad=None):\n",
        "    \"\"\"\n",
        "    Filtra una lista de entidades de Transformers por tipo de entidad.\n",
        "    \"\"\"\n",
        "    if tipo_entidad is None:\n",
        "        return entidades # Si no se especifica tipo, retorna todas.\n",
        "\n",
        "    entidades_filtradas = [ent for ent in entidades if ent['etiqueta'].lower() == tipo_entidad.lower()]\n",
        "    return entidades_filtradas\n",
        "\n",
        "# Ejemplo de uso del filtro\n",
        "texto_filtrar = \"El presidente se reuni√≥ con la Dra. L√≥pez en la Casa de Gobierno de Salta.\"\n",
        "entidades_texto_filtrar = analizar_entidades_transformers(texto_filtrar)\n",
        "\n",
        "print(f\"\\n--- Entidades de '{texto_filtrar}' ---\")\n",
        "for ent in entidades_texto_filtrar:\n",
        "    print(f\"  ‚Ä¢ {ent['texto']} ‚Üí {ent['etiqueta']}\")\n",
        "\n",
        "print(\"\\n--- Entidades filtradas (solo PERSONA) ---\")\n",
        "personas = filtrar_entidades_transformers(entidades_texto_filtrar, tipo_entidad='PER')\n",
        "for p in personas:\n",
        "    print(f\"  ‚Ä¢ {p['texto']}\")\n",
        "\n",
        "print(\"\\n--- Entidades filtradas (solo LUGAR) ---\")\n",
        "lugares = filtrar_entidades_transformers(entidades_texto_filtrar, tipo_entidad='LOC')\n",
        "for l in lugares:\n",
        "    print(f\"  ‚Ä¢ {l['texto']}\")\n",
        "print(\"-\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLlon0d_TjK3",
        "outputId": "8a7f79eb-fcfe-4c01-b5a6-ea87810dec7c"
      },
      "id": "GLlon0d_TjK3",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- EJERCICIO 3: Extensiones Avanzadas ---\n",
            "\n",
            "--- Procesamiento en Lote (Transformers) ---\n",
            "Procesando 4 textos con Transformers...\n",
            "Texto ID 0: 3 entidades\n",
            "Texto ID 1: 3 entidades\n",
            "Texto ID 2: 3 entidades\n",
            "Texto ID 3: 2 entidades\n",
            "\n",
            "--- Procesamiento en Lote (Gemini) ---\n",
            "Procesando 4 textos con Gemini...\n",
            "Texto ID 0: \n",
            "Aqu√≠ est√° la extracci√≥n de entidades nombradas del texto proporcionado, clasificadas seg√∫n las categor√≠as indicadas:\n",
            "\n",
            "*   **Juan** ‚Üí PERSONA ‚Üí Nombre de una persona.\n",
            "*   **Aerol√≠neas Argentinas** ‚Üí ORGANIZACI√ìN ‚Üí Nombre de una empresa de transporte a√©reo.\n",
            "*   **Caballito** ‚Üí LUGAR ‚Üí Nombre de un barrio de la Ciudad de Buenos Aires.\n",
            "\n",
            "---\n",
            "Texto ID 1: \n",
            "Aqu√≠ est√° la extracci√≥n y clasificaci√≥n de las entidades nombradas del texto proporcionado:\n",
            "\n",
            "*   Museo Nacional de Bellas Artes ‚Üí ORGANIZACI√ìN ‚Üí Nombre de un museo.\n",
            "*   Recoleta ‚Üí LUGAR ‚Üí Nombre de un barrio en Buenos Aires.\n",
            "*   Buenos Aires ‚Üí LUGAR ‚Üí Nombre de una ciudad.\n",
            "\n",
            "---\n",
            "Texto ID 2: \n",
            "*   AFA ‚Üí ORGANIZACI√ìN ‚Üí Asociaci√≥n del F√∫tbol Argentino.\n",
            "*   Ezeiza ‚Üí LUGAR ‚Üí Localidad de la provincia de Buenos Aires, Argentina.\n",
            "\n",
            "---\n",
            "Texto ID 3: \n",
            "*   Mercedes Sosa ‚Üí PERSONA ‚Üí Nombre de la cantante folcl√≥rica.\n",
            "*   Tucum√°n ‚Üí LUGAR ‚Üí Provincia argentina.\n",
            "\n",
            "---\n",
            "\n",
            "--- Exportando resultados a CSV ---\n",
            "Resultados de Transformers exportados a 'entidades_transformers.csv'\n",
            "Resultados de Gemini (salida raw) exportados a 'entidades_gemini.csv'\n",
            "\n",
            "--- Entidades de 'El presidente se reuni√≥ con la Dra. L√≥pez en la Casa de Gobierno de Salta.' ---\n",
            "  ‚Ä¢ Dra ‚Üí PER\n",
            "  ‚Ä¢ . L√≥pez ‚Üí PER\n",
            "  ‚Ä¢ Casa de Gobierno ‚Üí LOC\n",
            "  ‚Ä¢ Salta ‚Üí LOC\n",
            "\n",
            "--- Entidades filtradas (solo PERSONA) ---\n",
            "  ‚Ä¢ Dra\n",
            "  ‚Ä¢ . L√≥pez\n",
            "\n",
            "--- Entidades filtradas (solo LUGAR) ---\n",
            "  ‚Ä¢ Casa de Gobierno\n",
            "  ‚Ä¢ Salta\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "exercise_template",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bd8b6c7-d5e8-4a7e-fd66-003480d80cab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Conteo de entidades:\n",
            "{'PER': 2, 'ORG': 1, 'LOC': 1}\n"
          ]
        }
      ],
      "source": [
        "# üìù ESPACIO PARA TUS EJERCICIOS\n",
        "# Usa esta celda para experimentar y desarrollar tus soluciones\n",
        "\n",
        "# Ejemplo: Funci√≥n para contar entidades por tipo\n",
        "def contar_entidades_por_tipo(texto):\n",
        "    \"\"\"Cuenta entidades por categor√≠a usando Transformers\"\"\"\n",
        "    if not ner_pipeline:\n",
        "        return {}\n",
        "\n",
        "    entidades = ner_pipeline(texto)\n",
        "    conteo = {}\n",
        "\n",
        "    for ent in entidades:\n",
        "        tipo = ent['entity_group']\n",
        "        if tipo in conteo:\n",
        "            conteo[tipo] += 1\n",
        "        else:\n",
        "            conteo[tipo] = 1\n",
        "\n",
        "    return conteo\n",
        "\n",
        "# Probar la funci√≥n\n",
        "texto_prueba = \"Juan P√©rez trabaja en Google Argentina en Buenos Aires con Mar√≠a L√≥pez.\"\n",
        "print(\"üìä Conteo de entidades:\")\n",
        "print(contar_entidades_por_tipo(texto_prueba))\n",
        "\n",
        "# TODO: Agrega aqu√≠ tus propias funciones y experimentos"
      ],
      "id": "exercise_template"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "conclusion_section"
      },
      "source": [
        "---\n",
        "# üéØ Conclusi√≥n\n",
        "\n",
        "¬°Felicitaciones! Completaste el ejercicio de Reconocimiento de Entidades Nombradas.\n",
        "\n",
        "## üìö Lo que aprendiste:\n",
        "- ‚úÖ Implementar NER con modelos pre-entrenados\n",
        "- ‚úÖ Usar APIs de IA generativa para tareas de PLN\n",
        "- ‚úÖ Crear interfaces interactivas con Gradio\n",
        "- ‚úÖ Comparar diferentes enfoques de NER\n",
        "\n",
        "## üîÑ Pr√≥ximos pasos:\n",
        "1. Experiment√° con otros modelos de Hugging Face\n",
        "2. Prob√° con textos de diferentes dominios\n",
        "3. Implementa tu proyecto integrador\n",
        "4. Compart√≠ tus resultados con la clase\n",
        "\n",
        "## üìñ Recursos adicionales:\n",
        "- [Hugging Face Models](https://huggingface.co/models?pipeline_tag=token-classification&language=es)\n",
        "- [Gradio Documentation](https://gradio.app/docs/)\n",
        "- [Google AI Studio](https://ai.google.dev/)\n",
        "\n",
        "---\n",
        "**¬°√âxito en tu trabajo integrador!** üéìüöÄ"
      ],
      "id": "conclusion_section"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  }
}