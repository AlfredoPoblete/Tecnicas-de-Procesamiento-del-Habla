{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Clasificación de Sentimientos con una Red Neuronal Multicapa (PyTorch)\n",
        "##🎯 Objetivo\n",
        "En esta actividad vas a construir una red neuronal feedforward multicapa (MLP) usando PyTorch. El objetivo es entrenarla para que pueda clasificar frases en español como positivas o negativas.\n",
        "\n",
        "###Con esto vas a:\n",
        "\n",
        "* Comprender cómo se arma una red con varias neuronas.\n",
        "\n",
        "* Usar funciones de activación y entrenamiento automático.\n",
        "\n",
        "* Observar cómo mejora respecto al perceptrón simple de la Actividad 1."
      ],
      "metadata": {
        "id": "xPAukcLZZOqz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##🧰 1. Preparación del entorno\n",
        "Importamos PyTorch y NumPy para comenzar."
      ],
      "metadata": {
        "id": "bp3C44_ubQAZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "XUvckjUsa0TD"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##🗂️ 2. Datos de entrenamiento\n",
        "Usamos un conjunto de frases típicas de opiniones escritas en Argentina, etiquetadas como positivas (1) o negativas (0)."
      ],
      "metadata": {
        "id": "iuJrPnpWbUKJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frases = [\n",
        "    \"La verdad, este lugar está increible! Me encantó!\",\n",
        "    \"Una porquería de servicio, nunca más vengo\",\n",
        "    \"Me encantan las mesas, lastima el baño que es un desastre\",\n",
        "    \"Me enviaron un producto llegó dañado. Qué bajon\",\n",
        "    \"Todo impecable. De primera\",\n",
        "    \"Qué afano, me cuentearon con el producto\",\n",
        "    \"Muy conforme con el resultado final\",\n",
        "    \"No me gustó para nada la experiencia\",\n",
        "    \"Superó mis expectativas, ¡gracias!\",\n",
        "    \"No lo recomiendo, mala calidad\",\n",
        "    \"Me vino todo roto, exijo una devolucion\",\n",
        "    \"Muy buen servicio, lo recomiendo\",\n",
        "    \"Todo impecable, llego en tiempo y forma\"\n",
        "\n",
        "]\n",
        "\n",
        "etiquetas = np.array([1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1])  # 1 = Positivo, 0 = Negativo\n"
      ],
      "metadata": {
        "id": "HFBeK5ZGbYF5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##🧾 3. Construcción del vocabulario\n",
        "Definimos manualmente un vocabulario con palabras que suelen aparecer en frases de opinión con carga positiva o negativa."
      ],
      "metadata": {
        "id": "fZAj_cxtba9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulario = [\n",
        "    \"encantó\", \"encantan\", \"porquería\", \"bajon\", \"impecable\",\n",
        "    \"afano\", \"conforme\", \"no\", \"gusto\", \"gracias\",\n",
        "    \"recomiendo\", \"devolucion\", \"buen\", \"roto\", \"experiencia\", \"mala\"\n",
        "]"
      ],
      "metadata": {
        "id": "1KEXTHNUbalR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##🧠 4. Preprocesamiento: vectorización de las frases\n",
        "Cada frase se convierte en un vector binario (bag-of-words) que indica si contiene alguna de las palabras del vocabulario."
      ],
      "metadata": {
        "id": "OP-pT2DTbk5K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorizar(frase, vocabulario):\n",
        "    tokens = frase.lower().split()\n",
        "    return np.array([1 if palabra in tokens else 0 for palabra in vocabulario], dtype=np.float32)\n",
        "\n",
        "X_np = np.array([vectorizar(frase, vocabulario) for frase in frases], dtype=np.float32)\n",
        "y_np = etiquetas.astype(np.float32).reshape(-1, 1)\n",
        "\n",
        "# Convertimos a tensores de PyTorch\n",
        "X = torch.tensor(X_np)\n",
        "y = torch.tensor(y_np)"
      ],
      "metadata": {
        "id": "VaCF540vbnoR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##🧱 5. Definición del modelo (MLP)\n",
        "Vamos a crear un modelo simple con una capa oculta, activación ReLU, y una salida sigmoide para predicción binaria."
      ],
      "metadata": {
        "id": "3rQdH7w3bsXB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = len(vocabulario)\n",
        "hidden_size = 8\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_size, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "modelo = MLP()"
      ],
      "metadata": {
        "id": "sL_K2o15bvQZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##⚙️ 6. Entrenamiento del modelo\n",
        "Definimos la función de pérdida y el optimizador. Entrenamos por varias épocas."
      ],
      "metadata": {
        "id": "h4-EQNcib3tB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterio = nn.BCELoss()  # Binary Cross Entropy\n",
        "optimizador = optim.Adam(modelo.parameters(), lr=0.01)\n",
        "\n",
        "epocas = 200\n",
        "\n",
        "for epoca in range(epocas):\n",
        "    modelo.train()\n",
        "    salida = modelo(X)\n",
        "    loss = criterio(salida, y)\n",
        "\n",
        "    optimizador.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizador.step()\n",
        "\n",
        "    if (epoca + 1) % 10 == 0:\n",
        "        print(f\"Época {epoca+1}, Pérdida: {loss.item():.4f}\")\n"
      ],
      "metadata": {
        "id": "2epH-XRHb58g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f91f6c2d-d462-49b5-b002-612dfd249c76"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Época 10, Pérdida: 0.6700\n",
            "Época 20, Pérdida: 0.6036\n",
            "Época 30, Pérdida: 0.5114\n",
            "Época 40, Pérdida: 0.4118\n",
            "Época 50, Pérdida: 0.3287\n",
            "Época 60, Pérdida: 0.2723\n",
            "Época 70, Pérdida: 0.2394\n",
            "Época 80, Pérdida: 0.2214\n",
            "Época 90, Pérdida: 0.2118\n",
            "Época 100, Pérdida: 0.2062\n",
            "Época 110, Pérdida: 0.2029\n",
            "Época 120, Pérdida: 0.2008\n",
            "Época 130, Pérdida: 0.1993\n",
            "Época 140, Pérdida: 0.1982\n",
            "Época 150, Pérdida: 0.1974\n",
            "Época 160, Pérdida: 0.1967\n",
            "Época 170, Pérdida: 0.1962\n",
            "Época 180, Pérdida: 0.1958\n",
            "Época 190, Pérdida: 0.1955\n",
            "Época 200, Pérdida: 0.1952\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##🧪 7. Evaluación con frases nuevas\n",
        "Probamos la red con frases que no estaban en el entrenamiento, para ver cómo generaliza."
      ],
      "metadata": {
        "id": "YKZ5V6yhcDxI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frases_prueba = [\n",
        "    \"No me gustó la atención, bastante mala\",\n",
        "    \"Muy buena experiencia, todo excelente\",\n",
        "    \"Una estafa total, no lo recomiendo\",\n",
        "    \"Súper conforme con el servicio\",\n",
        "    \"Nada que ver con lo prometido, una decepción\"\n",
        "]\n",
        "\n",
        "# Vectorizamos las frases de prueba\n",
        "X_prueba_np = np.array([vectorizar(frase, vocabulario) for frase in frases_prueba], dtype=np.float32)\n",
        "X_prueba = torch.tensor(X_prueba_np)\n",
        "\n",
        "# Predicción\n",
        "modelo.eval()\n",
        "with torch.no_grad():\n",
        "    predicciones = modelo(X_prueba)\n",
        "\n",
        "# Mostrar resultados\n",
        "for frase, pred in zip(frases_prueba, predicciones):\n",
        "    clase = \"Positivo\" if pred.item() >= 0.5 else \"Negativo\"\n",
        "    print(f\"Frase: '{frase}' => Sentimiento predicho: {clase} ({pred.item():.2f})\")"
      ],
      "metadata": {
        "id": "gpIGfi-tcFPY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9b98249-f585-4459-bb44-a002f7adb48e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frase: 'No me gustó la atención, bastante mala' => Sentimiento predicho: Negativo (0.00)\n",
            "Frase: 'Muy buena experiencia, todo excelente' => Sentimiento predicho: Positivo (0.80)\n",
            "Frase: 'Una estafa total, no lo recomiendo' => Sentimiento predicho: Positivo (0.57)\n",
            "Frase: 'Súper conforme con el servicio' => Sentimiento predicho: Positivo (1.00)\n",
            "Frase: 'Nada que ver con lo prometido, una decepción' => Sentimiento predicho: Positivo (0.80)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##💬 Reflexión final\n",
        "###👉 ¿Qué aprendimos?\n",
        "\n",
        "* Cómo implementar y entrenar una red neuronal multicapa para análisis de sentimiento.\n",
        "\n",
        "* Cómo preprocesar texto en español usando bag-of-words.\n",
        "\n",
        "* Las ventajas del MLP frente al perceptrón simple.\n",
        "\n",
        "* Limitaciones: aún no capta el orden de las palabras ni el contexto secuencial.\n",
        "\n",
        "➡️ En la próxima actividad aprenderemos a usar redes recurrentes (LSTM) para incorporar secuencia y memoria en el procesamiento de texto. ¡Nos acercamos a modelos más cercanos al lenguaje humano!"
      ],
      "metadata": {
        "id": "138SwAUvcRnQ"
      }
    }
  ]
}