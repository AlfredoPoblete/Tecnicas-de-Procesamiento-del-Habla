{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ü§ó Aplicaciones pr√°cticas de Transformers con Hugging Face\n",
        "\n",
        "En esta clase vamos a usar modelos preentrenados en espa√±ol para resolver tareas reales de Procesamiento del Lenguaje Natural (PLN), sin necesidad de entrenar modelos desde cero.\n",
        "\n",
        "Trabajaremos con la librer√≠a `transformers` de Hugging Face, que permite usar modelos de tipo BERT, GPT y similares en muy pocas l√≠neas de c√≥digo.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "jFLeMnvKZbE2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "RZ_CCTg1ZZMX"
      },
      "outputs": [],
      "source": [
        "# Instalaci√≥n de Hugging Face Transformers (solo una vez)\n",
        "!pip install -q transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Cargando el pipeline de Hugging Face\n",
        "\n",
        "Hugging Face proporciona \"pipelines\" que encapsulan todo el proceso: tokenizaci√≥n, modelo y decodificaci√≥n. Solo ten√©s que indicar qu√© tarea quer√©s hacer.\n"
      ],
      "metadata": {
        "id": "eLn8knQiZktz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "2-F5MJPqZleF"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. An√°lisis de sentimiento en espa√±ol\n",
        "\n",
        "Vamos a usar un modelo entrenado para identificar si una frase expresa un **sentimiento positivo o negativo**. Este modelo fue entrenado con tweets en espa√±ol."
      ],
      "metadata": {
        "id": "ByWX-6UqZsGE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment = pipeline(\"sentiment-analysis\", model=\"finiteautomata/beto-sentiment-analysis\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Je8EvD0ip1q",
        "outputId": "ce04b0d1-7d4e-48c9-e6ec-5f5f049fbb88"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "frases = [\n",
        "    \"La verdad, este lugar est√° increible! Me encant√≥!\",\n",
        "    \"Una porquer√≠a de servicio, nunca m√°s vengo\",\n",
        "    \"Me encantan las mesas, lastima el ba√±o que es un desastre\",\n",
        "    \"Me enviaron un producto lleg√≥ da√±ado. Qu√© bajon\",\n",
        "    \"Todo impecable. De primera\",\n",
        "    \"Qu√© afano, me cuentearon con el producto\",\n",
        "    \"Muy conforme con el resultado final\",\n",
        "    \"No me gust√≥ para nada la experiencia\",\n",
        "    \"Super√≥ mis expectativas, ¬°gracias!\",\n",
        "    \"No lo recomiendo, mala calidad\",\n",
        "    \"Me vino todo roto, exijo una devolucion\",\n",
        "    \"Muy buen servicio, lo recomiendo\",\n",
        "    \"Todo impecable, llego en tiempo y forma\"\n",
        "]"
      ],
      "metadata": {
        "id": "k5xNiIU9Zrz6"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for frase in frases:\n",
        "    print(f\"{frase} ‚Üí {sentiment(frase)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ic9Jokw76dr",
        "outputId": "9a865950-71c9-4afb-daf0-747dee2fdc5c"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La verdad, este lugar est√° increible! Me encant√≥! ‚Üí [{'label': 'POS', 'score': 0.998566210269928}]\n",
            "Una porquer√≠a de servicio, nunca m√°s vengo ‚Üí [{'label': 'NEG', 'score': 0.9994451403617859}]\n",
            "Me encantan las mesas, lastima el ba√±o que es un desastre ‚Üí [{'label': 'NEG', 'score': 0.9644700884819031}]\n",
            "Me enviaron un producto lleg√≥ da√±ado. Qu√© bajon ‚Üí [{'label': 'NEG', 'score': 0.9993813037872314}]\n",
            "Todo impecable. De primera ‚Üí [{'label': 'POS', 'score': 0.9977364540100098}]\n",
            "Qu√© afano, me cuentearon con el producto ‚Üí [{'label': 'NEU', 'score': 0.544805645942688}]\n",
            "Muy conforme con el resultado final ‚Üí [{'label': 'POS', 'score': 0.9939767122268677}]\n",
            "No me gust√≥ para nada la experiencia ‚Üí [{'label': 'NEG', 'score': 0.9992014765739441}]\n",
            "Super√≥ mis expectativas, ¬°gracias! ‚Üí [{'label': 'POS', 'score': 0.9984914064407349}]\n",
            "No lo recomiendo, mala calidad ‚Üí [{'label': 'NEG', 'score': 0.9143223762512207}]\n",
            "Me vino todo roto, exijo una devolucion ‚Üí [{'label': 'NEG', 'score': 0.9983291029930115}]\n",
            "Muy buen servicio, lo recomiendo ‚Üí [{'label': 'POS', 'score': 0.99875807762146}]\n",
            "Todo impecable, llego en tiempo y forma ‚Üí [{'label': 'POS', 'score': 0.9573091268539429}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Clasificaci√≥n de texto por tema (*zero-shot*)\n",
        "\n",
        "¬øQuer√©s clasificar frases por categor√≠as sin entrenar un modelo? ¬°Esto es posible gracias al aprendizaje **zero-shot**!\n",
        "\n",
        "El modelo puede asociar un texto con una o m√°s **etiquetas** sugeridas por vos, aunque nunca fue entrenado espec√≠ficamente para esas clases."
      ],
      "metadata": {
        "id": "jLvgJTdNZyoM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = pipeline(\"zero-shot-classification\", model=\"Recognai/bert-base-spanish-wwm-cased-xnli\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4DDvK_aixWI",
        "outputId": "eadad7ae-2d30-41c2-db9e-8a3c26ee3c2e"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \"Tralalero tralala se hizo famoso por ser una rima particular de italia que trascendio por todo el mundo\"\n",
        "\n",
        "etiquetas = [\"animales\", \"personajes\", \"ni√±os\", \"espect√°culos\"]\n",
        "\n",
        "print(classifier(texto, candidate_labels=etiquetas))"
      ],
      "metadata": {
        "id": "UyR37nNRZ0xb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c119631-3a31-4783-b01c-0fc7cd33a635"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'sequence': 'Tralalero tralala se hizo famoso por ser una rima particular de italia que trascendio por todo el mundo', 'labels': ['personajes', 'espect√°culos', 'ni√±os', 'animales'], 'scores': [0.7077112197875977, 0.2328801304101944, 0.031039604917168617, 0.02836904115974903]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Resumen autom√°tico de textos\n",
        "\n",
        "Este pipeline toma un texto largo y genera un resumen breve en espa√±ol. Ideal para noticias, informes o textos descriptivos.\n",
        "\n",
        "Usamos un modelo BERT2BERT adaptado al espa√±ol."
      ],
      "metadata": {
        "id": "4GQztuQRZ4fi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summarizer = pipeline(\n",
        "    \"summarization\",\n",
        "    model=\"csebuetnlp/mT5_multilingual_XLSum\",\n",
        "    tokenizer=\"csebuetnlp/mT5_multilingual_XLSum\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVeW86swi4el",
        "outputId": "4705cef6-fffd-4207-ebe3-87ffcc37e413"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n",
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parrafo = \"\"\"\n",
        "El Ministerio de Salud confirm√≥ hoy que se ha logrado una reducci√≥n sostenida de casos de dengue en las √∫ltimas semanas.\n",
        "Las campa√±as de prevenci√≥n, sumadas a la llegada del fr√≠o, habr√≠an contribuido a esta baja. Sin embargo, se pide a la poblaci√≥n mantener las precauciones.\n",
        "\"\"\"\n",
        "\n",
        "resumen = summarizer(parrafo, max_length=50, min_length=20, do_sample=False)\n",
        "print(resumen[0]['summary_text'])\n"
      ],
      "metadata": {
        "id": "3akyvUJ8Z6g7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4c5e0a5-07a3-4f20-d708-5f38f627d715"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El n√∫mero de casos de dengue en Estados Unidos alcanz√≥ un nuevo r√©cord.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \"\"\"\n",
        "La inflaci√≥n en Argentina ha mostrado una leve desaceleraci√≥n en el √∫ltimo mes, seg√∫n el informe del INDEC.\n",
        "Sin embargo, los analistas advierten que la tendencia a√∫n no se revierte, y que podr√≠an esperarse aumentos para el pr√≥ximo trimestre.\n",
        "\"\"\"\n",
        "\n",
        "resumen = summarizer(texto, max_length=60, min_length=25, do_sample=False)\n",
        "print(resumen[0]['summary_text'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PTb3CEpj8vd",
        "outputId": "0e8f6837-2571-47d1-832a-f4d436d5e804"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El Fondo Monetario Internacional (INDEC) dijo que la inflaci√≥n en Argentina se ha recuperado de una desaceleraci√≥n en el √∫ltimo mes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Traducci√≥n autom√°tica (Espa√±ol ‚Üí Ingl√©s)\n",
        "\n",
        "Tambi√©n podemos usar modelos preentrenados para **traducir textos**. En este caso, usaremos uno especializado para traducir del espa√±ol al ingl√©s.\n"
      ],
      "metadata": {
        "id": "wi8qYvCBZ7PU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-es-en\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwMrWPLBkKKG",
        "outputId": "4b10e854-bec3-4b41-ef44-a78588aa7849"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/models/marian/tokenization_marian.py:177: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \"La familia es lo mas importante en este mundo.\"\n",
        "\n",
        "print(translator(texto)[0]['translation_text'])\n"
      ],
      "metadata": {
        "id": "6Hs_GEE2Z-3Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b436ac7-5fa9-4424-e065-0b165e3909d8"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Family is the most important thing in this world.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Generaci√≥n de texto en espa√±ol (GPT)\n",
        "\n",
        "Con un modelo tipo GPT entrenado en espa√±ol, podemos **generar texto a partir de un inicio dado**. Ideal para escribir contenido creativo, continuar frases, etc.\n"
      ],
      "metadata": {
        "id": "Aym3GgYraBhw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator = pipeline(\"text-generation\", model=\"PlanTL-GOB-ES/gpt2-base-bne\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_8fzsSBkOwl",
        "outputId": "e2cdd52d-e37d-4ad7-de04-108cdd1bb006"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Un dinosaurio es\"\n",
        "\n",
        "resultado = generator(prompt, max_length=100, num_return_sequences=1)\n",
        "print(resultado[0]['generated_text'])\n"
      ],
      "metadata": {
        "id": "QifU_lmfZ_50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fae048ef-88c2-460e-ad68-eed4a6bd14af"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=101) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Un dinosaurio es un ser vivo que est√° en el medio rural, pero es un dinosaurio. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Reflexi√≥n y discusi√≥n\n",
        "\n",
        "- ¬øCu√°l de estos pipelines te pareci√≥ m√°s sorprendente o √∫til?\n",
        "- ¬øCre√©s que estas herramientas podr√≠an usarse en un proyecto real? ¬øEn cu√°l?\n",
        "- ¬øNotaste errores o sesgos? ¬øPor qu√© cre√©s que aparecen?\n",
        "\n"
      ],
      "metadata": {
        "id": "fH5RSqBDaFul"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Actividad libre (opcional si hay tiempo)\n",
        "\n",
        "Explor√° uno de los pipelines y dise√±√° tu propio experimento:\n",
        "\n",
        "- Prob√° frases con sarcasmo o jergas locales.\n",
        "- Resum√≠ un art√≠culo de Wikipedia.\n",
        "- Traduc√≠ algo complejo (tecnol√≥gico, po√©tico, etc.).\n",
        "- Complet√° una frase usando estilo formal o informal.\n",
        "\n",
        "Al final compartimos los hallazgos m√°s interesantes con el grupo üëÄ\n",
        "\n"
      ],
      "metadata": {
        "id": "gC5dHmTaaOO7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "a) Probando frases random"
      ],
      "metadata": {
        "id": "fFJgfXgh8soV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frase_practica = [\n",
        "    \"Si te paras de manos, te paro el carro\",\n",
        "    \"Estan mansas las semitas ni√±o, mas buenas que la no se que\",\n",
        "    \"Quien sos vo, que te haces el mas importante\",\n",
        "    \"Estas mas linda que una patada en la nuca\",\n",
        "    \"Hablando de Roma, llego Roman\",\n",
        "    \"Que talca? quien pudiera irse temprano a la choza\",\n",
        "    \"Me pedi una milanga que estaban como ojota en el desierto\"\n",
        "]\n",
        "\n",
        "for frase in frase_practica:\n",
        "    print(f\"{frase} ‚Üí {sentiment(frase)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WV246zAI81TR",
        "outputId": "11262e2a-5d27-4d97-cfc7-35bf5829e3bd"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Si te paras de manos, te paro el carro ‚Üí [{'label': 'NEU', 'score': 0.9961426854133606}]\n",
            "Estan mansas las semitas ni√±o, mas buenas que la no se que ‚Üí [{'label': 'POS', 'score': 0.9983853101730347}]\n",
            "Quien sos vo, que te haces el mas importante ‚Üí [{'label': 'POS', 'score': 0.9013652801513672}]\n",
            "Estas mas linda que una patada en la nuca ‚Üí [{'label': 'POS', 'score': 0.9959981441497803}]\n",
            "Hablando de Roma, llego Roman ‚Üí [{'label': 'NEU', 'score': 0.9949650168418884}]\n",
            "Que talca? quien pudiera irse temprano a la choza ‚Üí [{'label': 'NEU', 'score': 0.9930123686790466}]\n",
            "Me pedi una milanga que estaban como ojota en el desierto ‚Üí [{'label': 'NEU', 'score': 0.9813180565834045}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "b) Resumir una pagina de wikipedia"
      ],
      "metadata": {
        "id": "CP_OumKi_l1H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texto_wiki = \"El hornero com√∫n (Furnarius rufus) es una especie de ave paseriforme de la familia de los furn√°ridos end√©mica de Am√©rica del Sur. Es un p√°jaro peque√±o que mide entre 16 y 23 cm de longitud y no presenta dimorfismo sexual aparente. Es un ave insect√≠vora que consigue su alimento mientras camina por el suelo. Su dieta consiste principalmente en peque√±os invertebrados como cole√≥pteros, grillos, mariposas y otros insectos. Se trata de una especie mon√≥gina que construye un caracter√≠stico nido de barro en √°rboles, construcciones y otras estructuras. La hembra deposita de tres a cuatro huevos, que ambos sexos ayudan a incubar. Al ser un ave de h√°bitos no migratorios, vive y se reproduce en su √°rea de residencia. Debido a su amplia √°rea de distribuci√≥n y su abundancia en incremento, el hornero com√∫n es clasificado como de preocupaci√≥n menor por la Uni√≥n Internacional para la Conservaci√≥n de la Naturaleza. Esta ave se favoreci√≥ con la presencia del ser humano, convirti√©ndose en el centro de muchas leyendas y canciones pertenecientes al folclore de Am√©rica del Sur. Adem√°s, los agricultores admiten al hornero com√∫n ya que este protege el sembrado de insectos da√±inos. Es el ave nacional de Argentina.[4]‚Äã Apareci√≥ en la moneda argentina de medio centavo de austral, acu√±ada en 1985, y a partir de 2017 en el billete de mil pesos.\"\n",
        "\n",
        "resumen = summarizer(texto_wiki, max_length=100, min_length=50, do_sample=False)\n",
        "print(resumen[0]['summary_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOu9nGwq_sCg",
        "outputId": "d81f8503-f414-4b60-ca0d-b2fd9aff8078"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El hornero com√∫n (Furnarius rufus) es un p√°jaro paseriforme de la familia de los furn√°ridos end√©mica de Am√©rica del Sur, que vive y se reproduce en su √°rea de residencia.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "c) Traduccion"
      ],
      "metadata": {
        "id": "4CmYKCUqBAWn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Transcript = \"Durante el entrenamiento, la red neuronal utiliza un bucle de retroalimentaci√≥n que funciona de la siguiente manera: Cada nodo intenta adivinar el siguiente nodo de la ruta. Se comprueba si la suposici√≥n es correcta. Los nodos asignan valores de peso m√°s altos a las rutas que conducen a m√°s suposiciones correctas y valores de peso m√°s bajos a las rutas de los nodos que conducen a suposiciones incorrectas.\"\n",
        "print(translator(Transcript)[0]['translation_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pN4qMwZTBGLi",
        "outputId": "5bb10fe0-fe85-48fa-9bb9-9d0a784ff894"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "During training, the neural network uses a feedback loop that works as follows: Each node tries to guess the next node of the path. It checks if the assumption is correct. The nodes assign higher weight values to the routes that lead to more correct assumptions and lower weight values to the routes of the nodes that lead to incorrect assumptions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "d) Completar una frase"
      ],
      "metadata": {
        "id": "ZOCqOyakBwx3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_2 = \"El amor es un sentimiento\"\n",
        "\n",
        "resultado = generator(prompt_2, max_length=100, num_return_sequences=1)\n",
        "print(resultado[0]['generated_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TGBcVptBq2L",
        "outputId": "ccb20fde-8697-437d-87b4-701ef0848e44"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=101) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El amor es un sentimiento que merece ser respetado, que no puede ser compartido, pero que es un sentimiento de amor que se debe hacer presente, que debe estar en el mundo de los ciudadanos, de los ciudadanos, de los ciudadanos... \n"
          ]
        }
      ]
    }
  ]
}